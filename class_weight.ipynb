{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Class Weights\n",
        "model VGG16 epoch:40"
      ],
      "metadata": {
        "id": "2NXj25-mAb8q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7uruh4Wjo9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftpaVBPqW5XD",
        "outputId": "e28dd764-6713-4fbf-96a9-928ab6d51a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file from Google Drive into a directory in Colab\n",
        "!unzip -q /content/drive/MyDrive/FER2013.zip -d /content/"
      ],
      "metadata": {
        "id": "mmmqltARXEBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "batch_size = 16\n",
        "\n",
        "train_data_dir = '/content/train'  # Update with correct subfolder if necessary\n",
        "test_data_dir = '/content/test'    # Update with correct subfolder if necessary\n",
        "\n",
        "datagen_train = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "train_generator = datagen_train.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "datagen_test = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.1,\n",
        "    channel_shift_range=0.0,\n",
        "    fill_mode='nearest',\n",
        "    horizontal_flip=True,\n",
        ")\n",
        "\n",
        "test_generator = datagen_test.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    batch_size=batch_size,\n",
        "    class_mode=\"sparse\",\n",
        "    shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRS8wWAuXI-1",
        "outputId": "ef38fe86-0c74-46b7-d917-a7adeb141dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "\n",
        "# Convert to dictionary\n",
        "class_weights_dict = dict(enumerate(class_weights))\n",
        "\n",
        "print(class_weights_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdIqErVU_8eK",
        "outputId": "45c35a31-68ea-41af-d6e3-4799511d74ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 1.0266046844269623, 1: 9.406618610747051, 2: 1.0010460615781582, 3: 0.5684387684387684, 4: 0.8260394187886635, 5: 0.8491274770777877, 6: 1.293372978330405}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model=ResNet50(weights=\"imagenet\",include_top=False,input_shape=(224,224,3))\n",
        "\n",
        "# Add layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512,activation=\"relu\")(x)\n",
        "x = Dense(256,activation=\"relu\")(x)\n",
        "x = Dense(128,activation=\"relu\")(x)\n",
        "x = Dense(64,activation=\"relu\")(x)\n",
        "output = Dense(7,activation=\"softmax\")(x)\n",
        "\n",
        "# final model\n",
        "model_classWeight=Model(inputs=base_model.input,outputs=output)\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False\n",
        "\n",
        "model_classWeight.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOiMpkuqACth",
        "outputId": "1837d837-d3ea-425c-b38e-efaa342eaa84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    min_delta=0.02,\n",
        ")\n",
        "\n",
        "checkpoint_callback_val = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'best_model_val_focal.keras',\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint_callback_train = tf.keras.callbacks.ModelCheckpoint(\n",
        "    'best_model_train_focal.keras',\n",
        "    monitor='accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "7t9zPr5DAIdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_classWeight.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=40,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size,\n",
        "    class_weight=class_weights_dict,  # Pass the class weights here\n",
        "    callbacks=[checkpoint_callback_val, checkpoint_callback_train, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1o9yNyRAM-I",
        "outputId": "2e2b26f2-b371-434a-dee4-bec393ebe869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1120 - loss: 2.1770\n",
            "Epoch 1: val_accuracy improved from -inf to 0.24805, saving model to best_model_val_ClassWeight.keras\n",
            "\n",
            "Epoch 1: accuracy improved from -inf to 0.10693, saving model to best_model_train_ClassWeight.keras\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 266ms/step - accuracy: 0.1120 - loss: 2.1769 - val_accuracy: 0.2480 - val_loss: 1.9447 - learning_rate: 5.0000e-04\n",
            "Epoch 2/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 77ms/step - accuracy: 0.1250 - loss: 1.7992"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.24805\n",
            "\n",
            "Epoch 2: accuracy improved from 0.10693 to 0.12500, saving model to best_model_train_ClassWeight.keras\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.1250 - loss: 1.7992 - val_accuracy: 0.0000e+00 - val_loss: 1.9473 - learning_rate: 5.0000e-04\n",
            "Epoch 3/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.1537 - loss: 1.9570\n",
            "Epoch 3: val_accuracy did not improve from 0.24805\n",
            "\n",
            "Epoch 3: accuracy improved from 0.12500 to 0.12850, saving model to best_model_train_ClassWeight.keras\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 265ms/step - accuracy: 0.1537 - loss: 1.9570 - val_accuracy: 0.1740 - val_loss: 1.9439 - learning_rate: 5.0000e-04\n",
            "Epoch 4/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:20\u001b[0m 78ms/step - accuracy: 0.1875 - loss: 1.8272\n",
            "Epoch 4: val_accuracy did not improve from 0.24805\n",
            "\n",
            "Epoch 4: accuracy improved from 0.12850 to 0.18750, saving model to best_model_train_ClassWeight.keras\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.1875 - loss: 1.8272 - val_accuracy: 0.0000e+00 - val_loss: 1.9434 - learning_rate: 5.0000e-04\n",
            "Epoch 5/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.1678 - loss: 1.9481\n",
            "Epoch 5: val_accuracy did not improve from 0.24805\n",
            "\n",
            "Epoch 5: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 246ms/step - accuracy: 0.1678 - loss: 1.9481 - val_accuracy: 0.1145 - val_loss: 1.9456 - learning_rate: 5.0000e-04\n",
            "Epoch 6/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:32\u001b[0m 85ms/step - accuracy: 0.0625 - loss: 2.7267\n",
            "Epoch 6: val_accuracy improved from 0.24805 to 1.00000, saving model to best_model_val_ClassWeight.keras\n",
            "\n",
            "Epoch 6: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.0625 - loss: 2.7267 - val_accuracy: 1.0000 - val_loss: 1.9332 - learning_rate: 5.0000e-04\n",
            "Epoch 7/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.1273 - loss: 1.9505\n",
            "Epoch 7: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 7: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 248ms/step - accuracy: 0.1273 - loss: 1.9505 - val_accuracy: 0.1145 - val_loss: 1.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 8/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:09\u001b[0m 72ms/step - accuracy: 0.0625 - loss: 1.6619\n",
            "Epoch 8: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 8: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37us/step - accuracy: 0.0625 - loss: 1.6619 - val_accuracy: 1.0000 - val_loss: 1.9388 - learning_rate: 5.0000e-04\n",
            "Epoch 9/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.1039 - loss: 1.9626\n",
            "Epoch 9: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 9: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 247ms/step - accuracy: 0.1039 - loss: 1.9626 - val_accuracy: 0.1145 - val_loss: 1.9455 - learning_rate: 5.0000e-04\n",
            "Epoch 10/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 77ms/step - accuracy: 0.1250 - loss: 1.6230\n",
            "Epoch 10: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 10: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.1250 - loss: 1.6230 - val_accuracy: 1.0000 - val_loss: 1.9415 - learning_rate: 5.0000e-04\n",
            "Epoch 11/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1174 - loss: 1.9470\n",
            "Epoch 11: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 11: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 249ms/step - accuracy: 0.1174 - loss: 1.9470 - val_accuracy: 0.1429 - val_loss: 1.9458 - learning_rate: 5.0000e-04\n",
            "Epoch 12/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:45\u001b[0m 92ms/step - accuracy: 0.1250 - loss: 1.6223\n",
            "Epoch 12: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 12: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 30ms/step - accuracy: 0.1250 - loss: 1.6223 - val_accuracy: 0.0000e+00 - val_loss: 1.9570 - learning_rate: 5.0000e-04\n",
            "Epoch 13/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.1451 - loss: 1.9485\n",
            "Epoch 13: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 13: accuracy did not improve from 0.18750\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m502s\u001b[0m 246ms/step - accuracy: 0.1451 - loss: 1.9485 - val_accuracy: 0.2475 - val_loss: 1.9454 - learning_rate: 5.0000e-04\n",
            "Epoch 14/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:06\u001b[0m 71ms/step - accuracy: 0.3125 - loss: 1.6589\n",
            "Epoch 14: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 14: accuracy improved from 0.18750 to 0.31250, saving model to best_model_train_ClassWeight.keras\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.3125 - loss: 1.6589 - val_accuracy: 0.0000e+00 - val_loss: 1.9480 - learning_rate: 5.0000e-04\n",
            "Epoch 15/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1616 - loss: 1.9465\n",
            "Epoch 15: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 15: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 247ms/step - accuracy: 0.1616 - loss: 1.9465 - val_accuracy: 0.1145 - val_loss: 1.9456 - learning_rate: 5.0000e-04\n",
            "Epoch 16/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:40\u001b[0m 89ms/step - accuracy: 0.2500 - loss: 2.7225\n",
            "Epoch 16: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 16: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85us/step - accuracy: 0.2500 - loss: 2.7225 - val_accuracy: 1.0000 - val_loss: 1.9433 - learning_rate: 5.0000e-04\n",
            "Epoch 17/40\n",
            "\u001b[1m1793/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.0515 - loss: 1.9919\n",
            "Epoch 17: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 17: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 246ms/step - accuracy: 0.0516 - loss: 1.9918 - val_accuracy: 0.1429 - val_loss: 1.9419 - learning_rate: 2.5000e-04\n",
            "Epoch 18/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 70ms/step - accuracy: 0.1875 - loss: 1.7902\n",
            "Epoch 18: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 18: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41us/step - accuracy: 0.1875 - loss: 1.7902 - val_accuracy: 0.0000e+00 - val_loss: 1.9481 - learning_rate: 2.5000e-04\n",
            "Epoch 19/40\n",
            "\u001b[1m1793/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1428 - loss: 1.9480\n",
            "Epoch 19: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 19: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 248ms/step - accuracy: 0.1428 - loss: 1.9480 - val_accuracy: 0.1740 - val_loss: 1.8959 - learning_rate: 2.5000e-04\n",
            "Epoch 20/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 70ms/step - accuracy: 0.3125 - loss: 1.4350\n",
            "Epoch 20: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 20: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35us/step - accuracy: 0.3125 - loss: 1.4350 - val_accuracy: 0.0000e+00 - val_loss: 1.9523 - learning_rate: 2.5000e-04\n",
            "Epoch 21/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.1678 - loss: 1.9401\n",
            "Epoch 21: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 21: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 246ms/step - accuracy: 0.1678 - loss: 1.9401 - val_accuracy: 0.1145 - val_loss: 1.9458 - learning_rate: 2.5000e-04\n",
            "Epoch 22/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59\u001b[0m 66ms/step - accuracy: 0.0625 - loss: 2.6718\n",
            "Epoch 22: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 22: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43us/step - accuracy: 0.0625 - loss: 2.6718 - val_accuracy: 1.0000 - val_loss: 1.9421 - learning_rate: 2.5000e-04\n",
            "Epoch 23/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1623 - loss: 1.9435\n",
            "Epoch 23: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 23: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 252ms/step - accuracy: 0.1623 - loss: 1.9435 - val_accuracy: 0.1145 - val_loss: 1.9457 - learning_rate: 2.5000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:57\u001b[0m 65ms/step - accuracy: 0.0625 - loss: 2.7247\n",
            "Epoch 24: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 24: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 31ms/step - accuracy: 0.0625 - loss: 2.7247 - val_accuracy: 1.0000 - val_loss: 1.9411 - learning_rate: 2.5000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.1566 - loss: 1.9264\n",
            "Epoch 25: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 25: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 250ms/step - accuracy: 0.1566 - loss: 1.9265 - val_accuracy: 0.1145 - val_loss: 1.9465 - learning_rate: 2.5000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 70ms/step - accuracy: 0.0625 - loss: 1.6609\n",
            "Epoch 26: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 26: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42us/step - accuracy: 0.0625 - loss: 1.6609 - val_accuracy: 1.0000 - val_loss: 1.9398 - learning_rate: 2.5000e-04\n",
            "Epoch 27/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.1168 - loss: 1.9505\n",
            "Epoch 27: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 27: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 251ms/step - accuracy: 0.1168 - loss: 1.9505 - val_accuracy: 0.1145 - val_loss: 1.9460 - learning_rate: 1.2500e-04\n",
            "Epoch 28/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 66ms/step - accuracy: 0.1875 - loss: 2.8636\n",
            "Epoch 28: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 28: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45us/step - accuracy: 0.1875 - loss: 2.8636 - val_accuracy: 1.0000 - val_loss: 1.9423 - learning_rate: 1.2500e-04\n",
            "Epoch 29/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.1027 - loss: 1.9488\n",
            "Epoch 29: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 29: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 251ms/step - accuracy: 0.1028 - loss: 1.9488 - val_accuracy: 0.1145 - val_loss: 1.9461 - learning_rate: 1.2500e-04\n",
            "Epoch 30/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 63ms/step - accuracy: 0.0000e+00 - loss: 1.6095\n",
            "Epoch 30: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 30: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 1.6095 - val_accuracy: 1.0000 - val_loss: 1.9433 - learning_rate: 1.2500e-04\n",
            "Epoch 31/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1109 - loss: 1.9439\n",
            "Epoch 31: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 31: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 247ms/step - accuracy: 0.1109 - loss: 1.9439 - val_accuracy: 0.0155 - val_loss: 1.9460 - learning_rate: 1.2500e-04\n",
            "Epoch 32/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 70ms/step - accuracy: 0.0625 - loss: 2.7181\n",
            "Epoch 32: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 32: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40us/step - accuracy: 0.0625 - loss: 2.7181 - val_accuracy: 0.0000e+00 - val_loss: 1.9452 - learning_rate: 1.2500e-04\n",
            "Epoch 33/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.0855 - loss: 1.9506\n",
            "Epoch 33: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 33: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 246ms/step - accuracy: 0.0855 - loss: 1.9505 - val_accuracy: 0.0155 - val_loss: 1.9462 - learning_rate: 1.2500e-04\n",
            "Epoch 34/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:52\u001b[0m 63ms/step - accuracy: 0.0000e+00 - loss: 1.6742\n",
            "Epoch 34: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 34: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 1.6742 - val_accuracy: 0.0000e+00 - val_loss: 1.9448 - learning_rate: 1.2500e-04\n",
            "Epoch 35/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.0652 - loss: 1.9552\n",
            "Epoch 35: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 35: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 249ms/step - accuracy: 0.0652 - loss: 1.9552 - val_accuracy: 0.1336 - val_loss: 1.9461 - learning_rate: 1.2500e-04\n",
            "Epoch 36/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:58\u001b[0m 66ms/step - accuracy: 0.1875 - loss: 2.6682\n",
            "Epoch 36: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 36: accuracy did not improve from 0.31250\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39us/step - accuracy: 0.1875 - loss: 2.6682 - val_accuracy: 0.0000e+00 - val_loss: 1.9451 - learning_rate: 1.2500e-04\n",
            "Epoch 37/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.1203 - loss: 1.9385\n",
            "Epoch 37: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 37: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 246ms/step - accuracy: 0.1203 - loss: 1.9385 - val_accuracy: 0.1336 - val_loss: 1.9460 - learning_rate: 6.2500e-05\n",
            "Epoch 38/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:07\u001b[0m 71ms/step - accuracy: 0.1250 - loss: 1.5906\n",
            "Epoch 38: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 38: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42us/step - accuracy: 0.1250 - loss: 1.5906 - val_accuracy: 0.0000e+00 - val_loss: 1.9450 - learning_rate: 6.2500e-05\n",
            "Epoch 39/40\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.1269 - loss: 1.9507\n",
            "Epoch 39: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 39: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 247ms/step - accuracy: 0.1269 - loss: 1.9507 - val_accuracy: 0.1145 - val_loss: 1.9460 - learning_rate: 6.2500e-05\n",
            "Epoch 40/40\n",
            "\u001b[1m   1/1794\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:01\u001b[0m 68ms/step - accuracy: 0.1875 - loss: 1.7894\n",
            "Epoch 40: val_accuracy did not improve from 1.00000\n",
            "\n",
            "Epoch 40: accuracy did not improve from 0.31250\n",
            "\u001b[1m1794/1794\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 32ms/step - accuracy: 0.1875 - loss: 1.7894 - val_accuracy: 1.0000 - val_loss: 1.9449 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    }
  ]
}